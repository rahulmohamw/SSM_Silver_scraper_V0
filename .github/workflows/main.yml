name: SMM Silver Price Scraper

on:
  schedule:
    # Run daily at 10:00 AM UTC (adjust timezone as needed)
    - cron: '0 10 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches: [main]
    paths: ['**.py', '**.yml']

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        
    - name: Create directories
      run: |
        mkdir -p csv screenshots logs
        
    - name: Run scraper
      run: |
        python main_scraper.py
        
    - name: List generated files
      run: |
        echo "CSV files:"
        ls -la csv/ || echo "No CSV files generated"
        echo "Screenshot files:"
        ls -la screenshots/ || echo "No screenshot files generated"
        echo "Log files:"
        ls -la logs/ || echo "No log files generated"
        
    - name: Upload CSV files
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: csv-data-${{ github.run_number }}
        path: csv/
        retention-days: 90
        
    - name: Upload screenshots
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: screenshots-${{ github.run_number }}
        path: screenshots/
        retention-days: 30
        
    - name: Upload logs
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: logs-${{ github.run_number }}
        path: logs/
        retention-days: 7
        
    - name: Commit and push data (optional)
      if: github.ref == 'refs/heads/main'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add csv/ screenshots/ logs/ || true
        git diff --staged --quiet || git commit -m "Update scraper data - $(date '+%Y-%m-%d %H:%M:%S')"
        git push || echo "Nothing to push"
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  notify:
    needs: scrape
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Notify success
      if: needs.scrape.result == 'success'
      run: echo "✅ Scraping completed successfully!"
      
    - name: Notify failure
      if: needs.scrape.result == 'failure'
      run: |
        echo "❌ Scraping failed!"
        exit 1
